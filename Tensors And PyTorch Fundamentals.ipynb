{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "613a0076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cd842db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7131f6c",
   "metadata": {},
   "source": [
    "# Creating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cfe908ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "88f75c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f08fda4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d6935438",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = torch.tensor([7,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "31525d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "402a998a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6d22bd07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9e005648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MATRIX\n",
    "MATRIX = torch.tensor([[7,8],\n",
    "                      [9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "284f7b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d148ee0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "324479ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#TENSOR\n",
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                        [3,6,9],\n",
    "                        [2,4,5]]])\n",
    "print(TENSOR.shape)\n",
    "print(TENSOR.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "12c12755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 6, 9],\n",
       "        [2, 4, 5]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e37e1e",
   "metadata": {},
   "source": [
    "### random tensors\n",
    "They are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data\n",
    "\n",
    "start with random numbers -> look at data -> update random numbers -> look at data -> repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1a9c2ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5168, 0.6604, 0.8712, 0.3973],\n",
       "        [0.3181, 0.7422, 0.0154, 0.3491],\n",
       "        [0.7668, 0.6368, 0.4766, 0.5314]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a random tensor of size (3,4)\n",
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1cc01b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "print(random_tensor.ndim)\n",
    "print(random_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "48fff0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a random tensor with similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size = (3,224,224)) #color channel, height, width\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ee0890b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #create a tensor of all zeros for a mask\n",
    "zero = torch.zeros(size=(3,4))\n",
    "zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5cf96117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create tensor of ones\n",
    "ones = torch.ones(size = (3,4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8d1715c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a range of tensors and tensors-like\n",
    "# use torch.range()\n",
    "torch.arange(0,10)\n",
    "one_to_ten = torch.arange(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c4b7696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating tensors like , create tensors that are similar to preexisting ones\n",
    "ten_zeros = torch.zeros_like(input = one_to_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0fa3e7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31be5e9d",
   "metadata": {},
   "source": [
    "# Tensor Datatypes\n",
    "**datatypes can cause errors\n",
    "1. Tensors not right datatype\n",
    "2. Tensors not right shape\n",
    "3. Tensors not on the right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3933c018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.0,6.0,9.0],\n",
    "                              dtype = torch.float32,\n",
    "                              device = None,\n",
    "                              requires_grad = False) #whether or not to track gradients with this tensors operations\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0ad16a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor= float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "82dd8960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor\n",
    "#tensors of different data types can be multiplied, but the result will take the type of the larger data type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "bb65ea59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3,6,9], dtype = torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "de95fde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor * int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "5ed5037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##getting info from tensors\n",
    "#get dtype using tensor.dtype\n",
    "#get shape using tensor.shape\n",
    "#get device using tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "cad79424",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_tensor = torch.rand(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4702d0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device tensor is on: cpu\n"
     ]
    }
   ],
   "source": [
    "#find out its details\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device tensor is on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1c6fe9",
   "metadata": {},
   "source": [
    "manipulation of tensors\n",
    "\n",
    "addition\n",
    "subtraction\n",
    "multiplication\n",
    "division\n",
    "matrix multiplication\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3f7d3608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#addition\n",
    "tensor_add = torch.tensor([1,2,3])\n",
    "tensor_add + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c64a41d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiplication\n",
    "tensor_mult = tensor_add.detach().clone()\n",
    "tensor_mult * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2228d41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#subtraction\n",
    "tensor_mult - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "61657534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch function for Tensor Multiplication, and Addition: tensor([10, 20, 30])\n",
      "tensor([11, 12, 13])\n"
     ]
    }
   ],
   "source": [
    "##PyTorch built-in functions\n",
    "print(f\"PyTorch function for Tensor Multiplication, and Addition: {torch.mul(tensor_mult, 10)}\")\n",
    "print(torch.add(tensor_add, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e0e2bf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "#matrix multiplication, element wise\n",
    "print(tensor_mult, \"*\", tensor_mult)\n",
    "print(f\"equals: {tensor_mult*tensor_mult}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1d0b0c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.04 µs ± 32.5 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "#dot product, since the product of 1x3 and 3x1 matrices will be 1x1\n",
    "\n",
    "%timeit torch.matmul(tensor_mult,tensor_mult)\n",
    "\n",
    "#runs faster than a for loop would"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "37ed38ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [199]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m Tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m      3\u001b[0m                         [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m],\n\u001b[1;32m      4\u001b[0m                         [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m      5\u001b[0m                         ])\n\u001b[1;32m      6\u001b[0m Tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m      7\u001b[0m                         [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m],\n\u001b[1;32m      8\u001b[0m                         [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m]\n\u001b[1;32m      9\u001b[0m                         ])\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43mTensor_B\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "#shapes for matrix mult\n",
    "Tensor_A = torch.tensor([[1,2],\n",
    "                        [2,3],\n",
    "                        [3,4]\n",
    "                        ])\n",
    "Tensor_B = torch.tensor([[1,2],\n",
    "                        [2,3],\n",
    "                        [3,4]\n",
    "                        ])\n",
    "torch.mm(Tensor_A,Tensor_B)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "315533e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2],\n",
       "         [2, 3],\n",
       "         [3, 4]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor_B, Tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "10e9320f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3],\n",
       "         [2, 3, 4]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor_B.T, Tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a343f905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  8, 11],\n",
       "        [ 8, 13, 18],\n",
       "        [11, 18, 25]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(Tensor_A, Tensor_B.T)\n",
    "# .T function converts to transpose so matrix mult works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1e599205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  10,  20,  30,  40,  50,  60,  70,  80,  90, 100])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding summary statistics of tensors\n",
    "#mean, min, max, sum, etc\n",
    "x = torch.arange(0,101,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "6312aaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(100), tensor(100))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#max\n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2a6cc36e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [213]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#average/mean\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, x\u001b[38;5;241m.\u001b[39mmean\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "#average/mean\n",
    "torch.mean(x), x.mean\n",
    "#it looks like x is a long dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f59789df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype\n",
    "#must be changed to appropriate dtype, the mean function can be used on tensors\n",
    "# that are of dtype floating point or complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ae6b6212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(50.), tensor(50.))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()\n",
    "#this type conversion will fix the issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "9818c73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(550), tensor(550))"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bf6149c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(10), tensor(10))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the index of max value\n",
    "torch.argmax(x), x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "841899e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the index of min value\n",
    "torch.argmin(x), x.argmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df67d1ca",
   "metadata": {},
   "source": [
    "Reshaping, stacking, squeezing, and unsqueezing tensors\n",
    "\n",
    "*Reshaping - reshapes an input tensor to a define shape\n",
    "*View- Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "\n",
    "*stacking -combines multiple tensors on top of each toehr or side by stack (vertical, horizontal)\n",
    "\n",
    "*Squeeze - remove all '1' dimensions from a tensor\n",
    "\n",
    "*Unsqueeze - add a '1' dimension to a target tensor\n",
    "\n",
    "*Permute - return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "80a1ca20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1.,10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "a7aa3f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add extra dimension\n",
    "x_reshaped = x.reshape(1,9)\n",
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0e3cc6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#change the view\n",
    "z = x.view(1,9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed9db97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing z changes x since the view of a tensor shares the same memory as the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "5064942e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:,0] = 5\n",
    "z,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "c8eb7a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "         [5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " torch.Size([9]))"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x,x,x,x], dim = 0)\n",
    "x_stacked, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "3575de0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " torch.Size([9]),\n",
       " torch.Size([9]))"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#squeeze and unsqueeze\n",
    "x_squeezed = torch.squeeze(x)\n",
    "x_squeezed, x_squeezed.shape, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "4ce05c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_unsqueezed = torch.unsqueeze(x_squeezed, dim = 0)\n",
    "x_unsqueezed, x_unsqueezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "1972abe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[5., 2., 3., 4., 5., 6., 7., 8., 9.]]]), torch.Size([1, 1, 9]))"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_super_unsqueezed = torch.unsqueeze(x_unsqueezed, dim = 0)\n",
    "x_super_unsqueezed, x_super_unsqueezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "0d5fc3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "#torch.permute returns a view of the original tensor with dimensions swapped\n",
    "x_original = torch.rand(size = (224,224,3)) #height, width, color channels (images)\n",
    "\n",
    "#permute the original tensor to rearrange the axis or dim\n",
    "\n",
    "x_permuted = x_original.permute(2, 0, 1) #shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\") #color channels, height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6f727a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#indexing (selecting data from tensors)\n",
    "\n",
    "#Indexing with PyTorch is similar to indexing with NumPy\n",
    "\n",
    "x = torch.arange(1, 10).reshape(1,3,3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5887c095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "dabeafae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), tensor([1, 2, 3]))"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0], x[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "113d9f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(1))"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][0], x[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "2ebee1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5), tensor(9))"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][1][1], x[0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "45e872b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using \":\" to select \"all\" of a target dimension\n",
    "x[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ccb5cc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get all values of 0th and 1st dimensions, but only index 1 of second dim\n",
    "x[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "ef59d8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get all values of the 0 dimension, but only the 1 index of the 1st and 2nd dimension\n",
    "x[:,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d484657d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get index 0 of 0th and 1st dimension and all values of second dimension\n",
    "x[0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "d7f2cb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 6, 9]])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return 2nd index of every element in dim 1 and 0\n",
    "x[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a817e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
